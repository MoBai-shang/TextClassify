{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "912b0132",
   "metadata": {},
   "source": [
    "# 修改config.json ，设置分类个数，我们这里设置num_labels = 22 表示22个类别分类，即\"num_labels\": 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e2ba986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "categories: 22\n",
      "\n",
      "\u0007download file bert-base-chinese-pytorch_model.bin now...\n",
      ">> Downloading 33.3%\n",
      "\u0007download file bert-base-chinese-vocab.txt now...\n",
      ">> Downloading 66.7%\n",
      "\u0007download file bert-base-chinese-config.json now...\n",
      ">> Downloading 100.0%\n",
      "Successfully downloaded\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "from six.moves import urllib\n",
    "import torch\n",
    "import sys\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "from transformers.data.processors.glue import glue_convert_examples_to_features as convert_examples_to_features\n",
    "from transformers.data.processors.utils import DataProcessor, InputExample\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from tqdm import trange\n",
    "import warnings\n",
    "\n",
    "def set_seed(args):\n",
    "    random.seed(args.seed)\n",
    "    np.random.seed(args.seed)\n",
    "    torch.manual_seed(args.seed)\n",
    "    if torch.cuda.is_available() > 0:\n",
    "        torch.cuda.manual_seed_all(args.seed)\n",
    "def download_and_extract(filepath, save_dir):\n",
    "    \"\"\"根据给定的URL地址下载文件\n",
    "    Parameter:\n",
    "        filepath: list 文件的URL路径地址\n",
    "        save_dir: str  保存路径\n",
    "    Return:\n",
    "        None\n",
    "    \"\"\"\n",
    "    for url, index in zip(filepath, range(len(filepath))):\n",
    "        filename = url.split('/')[-1]\n",
    "        print('\\n\\adownload file %s now...'%filename)\n",
    "        save_path = os.path.join(save_dir, filename)\n",
    "        urllib.request.urlretrieve(url, save_path)\n",
    "        sys.stdout.write('\\r>> Downloading %.1f%%' % (float(index + 1) / float(len(filepath)) * 100.0))\n",
    "        sys.stdout.flush()\n",
    "    print('\\nSuccessfully downloaded')\n",
    "\n",
    "def download_and_extract1(filepath,savedir):\n",
    "    #引用 requests文件\n",
    "    import requests\n",
    "    f=requests.get(filepath)\n",
    "    #下载文件\n",
    "    filename = filepath.split('/')[-1]\n",
    "    print('\\n\\adownload file %s now...'%filename)\n",
    "    with open(os.path.join(save_dir, filename),\"wb\") as code:\n",
    "         code.write(f.content)\n",
    "\n",
    "class TextDataProcessor(DataProcessor):\n",
    "    def __init__(self,train_csv,dev_csv,label_encoder):\n",
    "        super().__init__()\n",
    "        self.train_csv=train_csv\n",
    "        self.dev_csv=dev_csv\n",
    "        self.label_encoder=label_encoder\n",
    "        self._read_csv()\n",
    "        self.id_list=None\n",
    "        \n",
    "    \"\"\"Processor for the Book classification data set.\"\"\"\n",
    "    def _read_csv(self):\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        df=pd.read_csv(self.train_csv)\n",
    "        pkl_file = open(self.label_encoder, 'rb')\n",
    "        le_labels = pickle.load(pkl_file) \n",
    "        pkl_file.close()\n",
    "        del df['id']\n",
    "        df.dropna(subset=['category'],inplace=True)\n",
    "        df.dropna(thresh=2,inplace=True)\n",
    "        df['category'] = le_labels.transform(df['category'])\n",
    "        df.fillna(value='', inplace=True)\n",
    "        data=df.values\n",
    "        X,Y=data[:,:-1],data[:,-1]\n",
    "        self.labels=set(Y)\n",
    "        self.x_train, self.x_test, self.y_train, self.y_test = train_test_split(X, Y,test_size=0.2, random_state=0,stratify=Y)\n",
    "\n",
    "    def get_example_from_tensor_dict(self, tensor_dict):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return InputExample(\n",
    "            tensor_dict[\"idx\"].numpy(),\n",
    "            tensor_dict[\"sentence\"].numpy().decode(\"utf-8\"),\n",
    "            None,\n",
    "            str(tensor_dict[\"label\"].numpy()),\n",
    "        )\n",
    "    def get_train_examples(self):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        # return self._create_examples(self._read_tsv(os.path.join(data_dir, \"train.tsv\")), \"train\")\n",
    "        return self._create_examples(self.x_train,self.y_train, \"train\")\n",
    "\n",
    "    def get_dev_examples(self):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        df=pd.read_csv(self.dev_csv)\n",
    "        df.fillna(value='', inplace=True)\n",
    "        data=df.values\n",
    "        self.id_list=data[:,-1]\n",
    "        return self._create_examples(data[:,:-1],np.ones(data[:,-1].shape), \"dev\")\n",
    "\n",
    "    def get_test_examples(self):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return self._create_examples(self.x_test,self.y_test, \"test\")\n",
    "\n",
    "    def get_labels(self):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return self.labels\n",
    "    \n",
    "    def get_dev_ids(self):\n",
    "        return self.id_list\n",
    "\n",
    "    def _create_examples(self, X,Y, set_type):\n",
    "        \"\"\"Creates examples for the training and dev/test sets.\"\"\"\n",
    "        examples = []\n",
    "        for (i, x) in enumerate(X):\n",
    "            guid = \"%s-%s\" % (set_type, i)\n",
    "            text_a = x[0]+'。'+x[1]\n",
    "            text_b=None#x[0]\n",
    "            examples.append(InputExample(guid=guid, text_a=text_a, text_b=text_b, label=Y[i]))\n",
    "        return examples\n",
    "\n",
    "def load_and_cache_examples(args, processor, tokenizer, set_type):\n",
    "    # Load data features from cache or dataset file\n",
    "    assert set_type in ['train','dev','test']\n",
    "    if set_type == 'train':\n",
    "        print(\"Creating features from dataset file at {}\".format(args.train_csv))\n",
    "        examples = (\n",
    "            processor.get_train_examples()\n",
    "        )\n",
    "    if set_type == 'dev':\n",
    "        print(\"Creating features from dataset file at {}\".format(args.dev_csv))\n",
    "        examples = (\n",
    "            processor.get_dev_examples()\n",
    "        )\n",
    "    if set_type == 'test':\n",
    "        print(\"Creating features from dataset file at {}\".format(args.train_csv))\n",
    "        examples = (\n",
    "            processor.get_test_examples()\n",
    "        )\n",
    "    features = convert_examples_to_features(\n",
    "        examples,  # 原始数据\n",
    "        tokenizer,  #\n",
    "        label_list=label_list,\n",
    "        max_length=args.max_seq_length,  # 设置每个batch 最大句子长度\n",
    "        output_mode='classification' # 设置分类标记\n",
    "        #max_length=args.max_seq_length,  # 设置每个batch 最大句子长度\n",
    "        #pad_token=tokenizer.convert_tokens_to_ids([tokenizer.pad_token])[0],\n",
    "        #pad_token_segment_id=0,  # bert 分类设置0\n",
    "        #mask_padding_with_zero=True  # the attention mask will be filled by ``1``\n",
    "    )\n",
    "    # Convert to Tensors and build dataset\n",
    "    all_input_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long)\n",
    "    all_attention_mask = torch.tensor([f.attention_mask for f in features], dtype=torch.long)\n",
    "    all_token_type_ids = torch.tensor([f.token_type_ids for f in features], dtype=torch.long)\n",
    "    all_labels = torch.tensor([f.label for f in features], dtype=torch.long)\n",
    "    dataset = TensorDataset(all_input_ids, all_attention_mask, all_token_type_ids, all_labels)\n",
    "    return dataset\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n",
    "\n",
    "def train(model, data_loader, criterion, optimizer):\n",
    "    epoch_acc = 0.\n",
    "    epoch_loss = 0.\n",
    "    total_batch = 0\n",
    "    model.train()\n",
    "    #bar = tqdm(data_loader,desc='    batch',ncols=80,ascii=True)\n",
    "    for batch in data_loader:\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        input_ids, attention_mask, token_type_ids, labels = batch\n",
    "        # 预测\n",
    "        outputs = model(input_ids=input_ids,\n",
    "                        attention_mask=attention_mask,\n",
    "                        token_type_ids=token_type_ids)[0]\n",
    "        # 计算loss和acc\n",
    "        loss = criterion(outputs, labels)\n",
    "        _, y = torch.max(outputs, dim=1)\n",
    "        acc = (y == labels).float().mean()\n",
    "        if total_batch % 100 == 0:\n",
    "            print('Iter_batch[{}/{}]:'.format(total_batch, len(data_loader)),\n",
    "                  'Train Loss: ', \"%.3f\" % loss.item(), 'Train Acc:', \"%.3f\" % acc.item())\n",
    "        '''\n",
    "        if total_batch % 100 == 0:\n",
    "            bar.set_postfix(loss='%.3f'%loss.item(), Acc='%.3f'%acc.item())\n",
    "        '''\n",
    "        # 计算批次下总的acc和loss\n",
    "        epoch_acc += acc.item()  # 当前批次准确率\n",
    "        epoch_loss += loss.item()  # 当前批次loss\n",
    "        # 剃度下降\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        # scheduler.step()  # Update learning rate schedule\n",
    "        model.zero_grad()\n",
    "        total_batch += 1\n",
    "        # break\n",
    "    return epoch_acc / len(data_loader), epoch_loss / len(data_loader)\n",
    "\n",
    "\n",
    "def evaluate(model, data_loader, criterion):\n",
    "    epoch_acc = 0.\n",
    "    epoch_loss = 0.\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            input_ids, attention_mask, token_type_ids, labels = batch\n",
    "            # 预测\n",
    "            outputs = model(input_ids=input_ids,\n",
    "                            attention_mask=attention_mask,\n",
    "                            token_type_ids=token_type_ids)[0]\n",
    "            # 计算loss和acc\n",
    "            loss = criterion(outputs, labels)\n",
    "            _, y = torch.max(outputs, dim=1)\n",
    "            acc = (y == labels).float().mean()\n",
    "            # 计算批次下总的acc和loss\n",
    "            epoch_acc += acc.item()  # 当前批次准确率\n",
    "            epoch_loss += loss.item()  # 当前批次loss\n",
    "    return epoch_acc / len(data_loader), epoch_loss / len(data_loader)\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "class FocalLoss(nn.Module):\n",
    "    r\"\"\"\n",
    "        This criterion is a implemenation of Focal Loss, which is proposed in \n",
    "        Focal Loss for Dense Object Detection.\n",
    "\n",
    "            Loss(x, class) = - \\alpha (1-softmax(x)[class])^gamma \\log(softmax(x)[class])\n",
    "\n",
    "        The losses are averaged across observations for each minibatch.\n",
    "\n",
    "        Args:\n",
    "            alpha(1D Tensor, Variable) : the scalar factor for this criterion\n",
    "            gamma(float, double) : gamma > 0; reduces the relative loss for well-classiﬁed examples (p > .5), \n",
    "                                   putting more focus on hard, misclassiﬁed examples\n",
    "            size_average(bool): By default, the losses are averaged over observations for each minibatch.\n",
    "                                However, if the field size_average is set to False, the losses are\n",
    "                                instead summed for each minibatch.\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, class_num, alpha=None, gamma=2, size_average=True):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        if alpha is None:\n",
    "            self.alpha = Variable(torch.ones(class_num, 1))\n",
    "        else:\n",
    "            if isinstance(alpha, Variable):\n",
    "                self.alpha = alpha\n",
    "            else:\n",
    "                self.alpha = Variable(alpha)\n",
    "        self.gamma = gamma\n",
    "        self.class_num = class_num\n",
    "        self.size_average = size_average\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        N = inputs.size(0)\n",
    "        C = inputs.size(1)\n",
    "        P = F.softmax(inputs)\n",
    "        class_mask = inputs.data.new(N, C).fill_(0)\n",
    "        class_mask = Variable(class_mask)\n",
    "        ids = targets.view(-1, 1)\n",
    "        class_mask.scatter_(1, ids.data, 1.)\n",
    "        if inputs.is_cuda and not self.alpha.is_cuda:\n",
    "            self.alpha = self.alpha.cuda()\n",
    "        alpha = self.alpha[ids.data.view(-1)]\n",
    "        probs = (P*class_mask).sum(1).view(-1,1)\n",
    "        log_p = probs.log()\n",
    "        batch_loss = -alpha*(torch.pow((1-probs), self.gamma))*log_p \n",
    "        if self.size_average:\n",
    "            loss = batch_loss.mean()\n",
    "        else:\n",
    "            loss = batch_loss.sum()\n",
    "        return loss\n",
    "    \n",
    "warnings.filterwarnings('ignore')\n",
    "logger = logging.getLogger(__name__)\n",
    "# 初始化参数\n",
    "parser = argparse.ArgumentParser()\n",
    "args = parser.parse_args(args=[])  # 在jupyter notebook中，args不为空\n",
    "\n",
    "#########################################################################\n",
    "#                               update                                  #\n",
    "#_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_#\n",
    "args.train_csv = \"dataset/Summary-train.csv\"\n",
    "args.dev_csv = \"dataset/validation.csv\"\n",
    "#find out pretrained model file at https://huggingface.co/models\n",
    "args.pretrain_files=[\"https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-pytorch_model.bin\",\n",
    "                     \"https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-vocab.txt\",\n",
    "                     \"https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-config.json\"]\n",
    "\n",
    "args.pretrain_model='bert-base-chinese'\n",
    "args.model_type = \"bert\"\n",
    "args.task_name = \"BookClassification\"\n",
    "args.output_dir = \"./outputs\"\n",
    "args.max_seq_length = 64\n",
    "args.batch_size = 64\n",
    "args.n_epochs=6\n",
    "args.lr = 5e-5\n",
    "#########################################################################\n",
    "\n",
    "args.label_encoder=args.output_dir+'/category_encoder.pkl'\n",
    "args.save_model=args.output_dir+'/'+args.model_type.split('/')[-1]+'_model.pt'\n",
    "args.pretrain_path=os.path.join(args.output_dir,args.pretrain_model)\n",
    "args.do_train = True\n",
    "args.do_eval = True\n",
    "args.warmup_steps = 0\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "args.device = device\n",
    "args.seed = 1234\n",
    "\n",
    "set_seed(args)  # Added here for reproductibility\n",
    "if not os.path.exists(args.output_dir):\n",
    "    os.makedirs(args.output_dir)\n",
    "if not os.path.exists(args.label_encoder):\n",
    "    le = LabelEncoder()\n",
    "    args.labels= set(le.fit_transform(pd.read_csv(args.train_csv)['category']))\n",
    "    #exporting the departure encoder\n",
    "    output = open(args.label_encoder, 'wb')\n",
    "    pickle.dump(le, output)\n",
    "    output.close()\n",
    "    print('categories:',len(args.labels))\n",
    "\n",
    "#if there isn't local pretrained model file,need to dowmload them\n",
    "if not os.path.exists(args.pretrain_path):\n",
    "    os.makedirs(args.pretrain_path)\n",
    "    download_and_extract(args.pretrain_files,args.pretrain_path)\n",
    "elif len(os.listdir(args.pretrain_path))<3:\n",
    "    download_and_extract(args.pretrain_files,args.pretrain_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44235d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label:  {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21}\n",
      "-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_\n",
      "\u0007Loading Tokenizer ..........\n",
      "\u0007Loading train dataset ..........\n",
      "Creating features from dataset file at dataset/Summary-train.csv\n",
      "\u0007Loading test dataset ..........\n",
      "Creating features from dataset file at dataset/Summary-train.csv\n",
      "\u0007Loading pretraining model ..........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./outputs\\bert-base-chinese\\bert-base-chinese-pytorch_model.bin were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ./outputs\\bert-base-chinese\\bert-base-chinese-pytorch_model.bin and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u0007Loading done!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1. 定义数据处理器\n",
    "processor = TextDataProcessor(args.train_csv,args.dev_csv,args.label_encoder)\n",
    "args.label_list = processor.get_labels()\n",
    "label_list = processor.get_labels()\n",
    "num_labels = len(args.label_list)\n",
    "print('label: ', args.label_list)\n",
    "print('-_' * 30)\n",
    "print('\\aLoading Tokenizer','.'*10)\n",
    "tokenizer = BertTokenizer.from_pretrained( os.path.join(args.pretrain_path, 'bert-base-chinese-vocab.txt') )\n",
    "print('\\aLoading train dataset','.'*10)\n",
    "train_dataset = load_and_cache_examples(args, processor, tokenizer, 'train')\n",
    "print('\\aLoading test dataset','.'*10)\n",
    "test_dataset = load_and_cache_examples(args, processor, tokenizer, 'test')\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=args.batch_size, shuffle=False)\n",
    "\n",
    "N_EPOCHS = args.n_epochs\n",
    "t_total = len(train_dataloader) // N_EPOCHS\n",
    "# 4. 模型定义\n",
    "print('\\aLoading pretraining model','.'*10)\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    os.path.join(args.pretrain_path, 'bert-base-chinese-pytorch_model.bin'),\n",
    "    config=os.path.join(args.pretrain_path, 'bert-base-chinese-config.json'),num_labels=len(args.label_list))\n",
    "#model = BertForSequenceClassification.from_pretrained('pytorch_model.bin',\n",
    "#    config= 'config.json',num_labels=len(args.label_list),catch_dir='catch')\n",
    "\n",
    "model.to(device)\n",
    "# 梯度更新算法AdamW\n",
    "no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "optimizer_grouped_parameters = [\n",
    "    {\n",
    "        \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "        \"weight_decay\": 0.0,\n",
    "    },\n",
    "    {\"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0},\n",
    "]\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=args.lr,\n",
    "                  correct_bias=False)  \n",
    "# loss_func\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "print('\\aLoading done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77bff496",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "\u0007Epoch|train:   0%|                                       | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter_batch[0/1286]: Train Loss:  3.363 Train Acc: 0.016\n",
      "Iter_batch[100/1286]: Train Loss:  0.865 Train Acc: 0.750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u0007Epoch|train:   0%|                                       | 0/6 [00:37<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_12804/991040494.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mbar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN_EPOCHS\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mncols\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m80\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdesc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'\\aEpoch|train'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbar\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mtrain_acc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0mval_acc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mbest_valid_loss\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_12804/369335549.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, data_loader, criterion, optimizer)\u001b[0m\n\u001b[0;32m    189\u001b[0m         '''\n\u001b[0;32m    190\u001b[0m         \u001b[1;31m# 计算批次下总的acc和loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 191\u001b[1;33m         \u001b[0mepoch_acc\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# 当前批次准确率\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    192\u001b[0m         \u001b[0mepoch_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# 当前批次loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m         \u001b[1;31m# 剃度下降\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# 5. 模型训练\n",
    "#print('模型训练开始： ')\n",
    "logger.info(\"***** Running training *****\")\n",
    "logger.info(\"  train num examples = %d\", len(train_dataloader))\n",
    "#logger.info(\"  dev num examples = %d\", len(dev_dataloader))\n",
    "logger.info(\"  test num examples = %d\", len(test_dataloader))\n",
    "logger.info(\"  Num Epochs = %d\", args.n_epochs)\n",
    "best_valid_loss = float('inf')\n",
    "bar=trange(N_EPOCHS,ncols=80,desc='\\aEpoch|train')\n",
    "for epoch in bar:\n",
    "    train_acc, train_loss = train(model, train_dataloader, criterion, optimizer)\n",
    "    val_acc, val_loss = evaluate(model, test_dataloader, criterion)\n",
    "    if val_loss < best_valid_loss:\n",
    "        print('loss increasing->')\n",
    "        best_valid_loss = val_loss\n",
    "        torch.save(model.state_dict(),args.save_model)\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.3f}%')\n",
    "    print(f'\\t Val. Loss: {val_loss:.3f} |  Val. Acc: {val_acc * 100:.3f}%')\n",
    "    time.sleep(0.5)\n",
    "# evaluate\n",
    "model.load_state_dict(torch.load(args.save_model))\n",
    "test_acc, test_loss = evaluate(model, test_dataloader, criterion)\n",
    "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cae31ed-2f96-48ff-8569-0ad09cb89d50",
   "metadata": {},
   "source": [
    "# the follow code need to be checked for the order of predicted answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bc38d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit(args,model, data_loader,submit_csv):\n",
    "    pkl_file = open(args.label_encoder, 'rb')\n",
    "    le = pickle.load(pkl_file) \n",
    "    pkl_file.close()\n",
    "    res=[]\n",
    "    for batch in tqdm(data_loader,desc='predict...'):\n",
    "        batch = tuple(t.to(args.device) for t in batch)\n",
    "        input_ids, attention_mask, token_type_ids, labels = batch\n",
    "        # 预测\n",
    "        outputs = model(input_ids=input_ids,\n",
    "                        attention_mask=attention_mask,\n",
    "                        token_type_ids=token_type_ids)[0]\n",
    "        _, y = torch.max(outputs, dim=1)\n",
    "        res.append(le.inverse_transform(y.data.cpu().numpy()).reshape(-1,1))\n",
    "    sub=np.vstack(res)\n",
    "    sub=np.hstack([args.id_list.reshape(-1,1),sub.reshape(-1,1)])\n",
    "    df=pd.DataFrame(sub,columns=['id','label'])\n",
    "    df.to_csv(submit_csv,index=0) #,index=0不保存行索引\n",
    "\n",
    "dev_dataset = load_and_cache_examples(args, processor, tokenizer, 'dev')\n",
    "dev_dataloader = DataLoader(dev_dataset, batch_size=args.batch_size//16, shuffle=False)\n",
    "args.id_list=processor.get_dev_ids()\n",
    "model.load_state_dict(torch.load(args.save_model))\n",
    "submit(args,model, dev_dataloader,args.output_dir+'/submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011e7f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_(args,model, train_dataloader,test_dataloader,submit_csv):\n",
    "    pkl_file = open(args.label_encoder, 'rb')\n",
    "    le = pickle.load(pkl_file) \n",
    "    pkl_file.close()\n",
    "    res=[]\n",
    "\n",
    "    for batch in tqdm(train_dataloader,desc='predict...'):\n",
    "        batch = tuple(t.to(args.device) for t in batch)\n",
    "        input_ids, attention_mask, token_type_ids, labels = batch\n",
    "        # 预测\n",
    "        outputs = model(input_ids=input_ids,\n",
    "                        attention_mask=attention_mask,\n",
    "                        token_type_ids=token_type_ids)[0]\n",
    "        _, y = torch.max(outputs, dim=1)\n",
    "        res.extend(le.inverse_transform(y.data.cpu().numpy()))\n",
    "\n",
    "\n",
    "    for batch in tqdm(test_dataloader,desc='predict...'):\n",
    "        batch = tuple(t.to(args.device) for t in batch)\n",
    "        input_ids, attention_mask, token_type_ids, labels = batch\n",
    "        # 预测\n",
    "        outputs = model(input_ids=input_ids,\n",
    "                        attention_mask=attention_mask,\n",
    "                        token_type_ids=token_type_ids)[0]\n",
    "        _, y = torch.max(outputs, dim=1)\n",
    "        res.extend(le.inverse_transform(y.data.cpu().numpy()))\n",
    "    df=pd.read_csv(args.train_csv)\n",
    "    del df['id']\n",
    "    df.dropna(how='any',inplace=True)\n",
    "    sub= pd.Series(res, name='predict', index=df.index)\n",
    "    df= pd.concat([df, sub], axis=1)\n",
    "    df.to_csv(submit_csv,index=0) #,index=0不保存行索引\n",
    "\n",
    "\n",
    "\n",
    "model.load_state_dict(torch.load('outputs/bert-model(seq=128,val=0.89).pt'))\n",
    "predict_(args,model, train_dataloader,test_dataloader,args.output_dir+'/train-predict.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6d962d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data num 83479\n",
      "right num 79453\n",
      "T    548\n",
      "K    452\n",
      "I    394\n",
      "G    365\n",
      "F    362\n",
      "C    336\n",
      "B    308\n",
      "H    277\n",
      "D    267\n",
      "J    156\n",
      "N    102\n",
      "O     74\n",
      "U     69\n",
      "E     55\n",
      "X     54\n",
      "Z     52\n",
      "P     37\n",
      "A     36\n",
      "R     36\n",
      "V     18\n",
      "S     15\n",
      "Q     13\n",
      "Name: category, dtype: int64\n",
      "22\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('train-predict.csv')\n",
    "print('data num',len(df))\n",
    "print('right num',sum(df['category']==df['predict']))\n",
    "s=df[df['category']!=df['predict']]\n",
    "count=s['category'].value_counts()\n",
    "print(count)\n",
    "count.plot(kind='pie')\n",
    "print(len(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390202e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_csv):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    import pandas as pd\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    import numpy as np\n",
    "    df=pd.read_csv(data_csv,header=0)\n",
    "    le = LabelEncoder()\n",
    "    '''\n",
    "    if 'id' in df.columns:\n",
    "        del df['id']\n",
    "    df.dropna(subset=['category'],inplace=True)\n",
    "    df.dropna(thresh=2,inplace=True)\n",
    "    df.fillna(value='', inplace=True)\n",
    "    categories= set(df['category'])\n",
    "    #exporting the departure encoder\n",
    "    df.rename(columns={'context':'text','category':'labels'},inplace=True)\n",
    "    X,Y=df['text'],df['labels']\n",
    "    '''\n",
    "    \n",
    "    df['category'] = le.fit_transform(df['category'])\n",
    "    \n",
    "    X,Y=df['title'],df['category']\n",
    "    x_train, x_test, y_train,y_test = train_test_split(X, Y,test_size=0.2, random_state=0,stratify=Y)\n",
    "    train_df=pd.concat([x_train,y_train],axis=1)\n",
    "    test_df=pd.concat([x_test,y_test],axis=1)\n",
    "    return train_df,test_df\n",
    "train_df,eval_df=load_data('data/v3.csv')\n",
    "print(train_df.shape,eval_df.shape)\n",
    "print(train_df.values[0])\n",
    "train_df.to_csv('data/split-train-title.csv',index=0)\n",
    "eval_df.to_csv('data/split-test-title.csv',index=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
