{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfd234a9",
   "metadata": {},
   "source": [
    "# Begin at here\n",
    "### 本程序为建模主程序，执行本程序前请运行数据预处理程序“Text_pre_processor”，对比赛数据进行预处理，包括train.csv和validation.csv\n",
    "### 程序编写设备为64位windows 7\n",
    "### 运行环境为python 3.8 jupyter，运行需要cuda支持\n",
    "### 代码执行过程：依次执行以下每一部分代码块（一键执行全部）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95aa258",
   "metadata": {},
   "source": [
    "## 1 配置环境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6380281",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from simpletransformers.classification import ClassificationModel\n",
    "except ImportError:\n",
    "    !pip install simpletransformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc67fb45",
   "metadata": {},
   "source": [
    "## 2 加载数据集（训练数据与测试数据）\n",
    "####  注：数据文件路径名为'data/Summary-tra.csv'，是采用代码“Text_pre_processor”对比赛源始数据进行数据预处理后的数据，执行以下代码前请确保使用的数据已经经过数据预处理，如果使用源始数据直接进行加载操作，模型得分影响不会很大"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56185a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(102832, 2) (102832, 2)\n",
      "['传热学主要介绍了导热、对流和辐射等课程内容的相关概念、定律、公式等。全书的重点是相关内容的例题详解和补充习题。带有答案的补充习题可帮助读者自我评估学习状况。'\n",
      " 17]\n"
     ]
    }
   ],
   "source": [
    "def load_data(data_csv):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    import pandas as pd\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    import numpy as np\n",
    "    import os\n",
    "    import pickle\n",
    "    df=pd.read_csv(data_csv,header=0)\n",
    "    \n",
    "    if 'id' in df.columns:\n",
    "        del df['id']\n",
    "    df.dropna(subset=['category'],inplace=True)\n",
    "    #exporting the departure encoder\n",
    "    if 'context' not in df.columns:\n",
    "        df.dropna(thresh=2,inplace=True)\n",
    "        df.fillna(value='', inplace=True)\n",
    "        df['context']=df['title']+df['summary']\n",
    "        del df['title']\n",
    "        del df['summary']\n",
    "    label_encoder='outputs/category_encoder.pkl'\n",
    "    if not os.path.exists(label_encoder):\n",
    "        if not os.path.exists('outputs'):\n",
    "            os.makedirs('outputs')\n",
    "        le = LabelEncoder()\n",
    "        df['category'] = le.fit_transform(df['category'])\n",
    "        output = open(label_encoder, 'wb')\n",
    "        pickle.dump(le, output)\n",
    "        output.close()\n",
    "    else:\n",
    "        le = pickle.load(open('outputs/category_encoder.pkl', 'rb'))\n",
    "        df['category'] = le.fit_transform(df['category'])\n",
    "    df.rename(columns={'context':'text','category':'labels'},inplace=True)\n",
    "    X,Y=df['text'],df['labels']\n",
    "    x_train, x_test, y_train,y_test = train_test_split(X, Y,test_size=0.3, random_state=10,stratify=Y)\n",
    "    train_df=pd.concat([x_train,y_train],axis=1)\n",
    "    test_df=pd.concat([x_test,y_test],axis=1)\n",
    "    \n",
    "    ###############################33\n",
    "    tra=pd.concat([X,Y],axis=1)\n",
    "    return tra,tra\n",
    "    \n",
    "    return train_df,test_df\n",
    "train_df,eval_df=load_data('data/Summary-tra.csv')#加载测试数据与训练数据\n",
    "print(train_df.shape,eval_df.shape)#输出数据样本举例\n",
    "print(train_df.values[1])\n",
    "#train_df.to_csv('data/split-train-title.csv',index=0)\n",
    "#eval_df.to_csv('data/split-test-title.csv',index=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a0bc9f-518f-409e-8389-57bd2e876434",
   "metadata": {},
   "source": [
    "## 3 搭建模型框架并建模，模型选择可详见https://huggingface.co/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08a9bd33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at hfl/chinese-xlnet-mid were not used when initializing XLNetForSequenceClassification: ['lm_loss.bias', 'lm_loss.weight']\n",
      "- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at hfl/chinese-xlnet-mid and are newly initialized: ['logits_proj.weight', 'sequence_summary.summary.bias', 'sequence_summary.summary.weight', 'logits_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82028e7f01ef4e4bb1b770c92222ad86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/102832 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea7667556ac84463b1485a7b107482ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd4d0f5f2e8c4c9593850a055a60578b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 10:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dcab3a0c0714af4aaa77de9fdbda3dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 10:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e2ffcafcfec43688fee5b370f2f8964",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 10:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1361777ec764426bf5151aec91c8932",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 3 of 10:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dd948d5f3dd4a66b3cd3849994c8eb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 4 of 10:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1bec3ad4d9548dc83ec65a1cf290d3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 5 of 10:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f37fabc7c7545b297f32973b25de93c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 6 of 10:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f33736e505254711b3997ab13db835ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 7 of 10:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "553cc7b9a2f0482d96969811feaf9d72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 8 of 10:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86dd4e7b8faf488889a10389b4ef5f9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 9 of 10:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(16070, 0.15064805236368184)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from simpletransformers.classification import ClassificationModel\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "# Create a TransformerModel\n",
    "#model_type可以是['bert'，'xlnet'，'xlm'，'roberta'，'distilbert']之一。\n",
    "#要加载以前保存的模型而不是默认模型的模型，可以将model_name更改为包含已保存模型的目录的路径。\n",
    "model = ClassificationModel('xlnet', 'hfl/chinese-xlnet-mid', num_labels=22,use_cuda=True,\n",
    "                         args={'learning_rate':5e-5, 'num_train_epochs': 10,'use_early_stopping':True,'save_eval_checkpoints':False,\n",
    "                               'reprocess_input_data': True, 'overwrite_output_dir': True,'save_model_every_epoch':False,'n_gpu':-1,\n",
    "                              'max_seq_length':64, 'train_batch_size': 64,'best_model_dir':'outputs/final_best'})\n",
    "# Train the model\n",
    "model.train_model(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a97451",
   "metadata": {},
   "source": [
    "## 4 模型性能评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe7a8872",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "693a1f74225f40ad90253f92391c3db9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/102832 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45b6e3a773e84029a881f95ed49c94b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/12854 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mcc': 0.9993067969145869, 'f1': 0.9994165240392096, 'acc': 0.9994165240392096, 'eval_loss': 0.001716306218328234}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "#定义评估指标之一：f1\n",
    "def f1_multiclass(labels, preds):\n",
    "      return f1_score(labels, preds, average='micro')\n",
    "\n",
    "#评估\n",
    "result, model_outputs, wrong_predictions = model.eval_model(eval_df, f1=f1_multiclass, acc=accuracy_score)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b8328a-3195-4829-9fab-84bb7192e063",
   "metadata": {},
   "source": [
    "##  5 加载模型并预测测试集标签\n",
    "### 注：加载验证集数据前，需要运行数据预处理程序，对验证集数据采取数据预处理，这里加载的验证集路径为“data/Summary-val.csv”\n",
    "#### 加载以前保存的模型而不是默认模型的模型，可以将model_name更改为包含已保存模型的目录的路径。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af703c7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83961196b5d04b9986c7c7d5d97016a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/34045 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9189ff141e04998a6b861d4060ae159",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4256 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u0007done!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from simpletransformers.classification import ClassificationModel\n",
    "model = ClassificationModel('xlnet', 'outputs', num_labels=22,use_cuda=True,\n",
    "                         args={'learning_rate':5e-5, 'num_train_epochs': 10,'use_early_stopping':True,\n",
    "                               'reprocess_input_data': True, 'overwrite_output_dir': True,'save_model_every_epoch':False,\n",
    "                              'max_seq_length': 64, 'train_batch_size': 64})\n",
    "\n",
    "df=pd.read_csv('data/Summary-val.csv')\n",
    "if 'context' not in df.columns:\n",
    "    df.fillna(value='', inplace=True)\n",
    "    df['context']=df['title']+df['summary']\n",
    "pre_df=list(df['context'])\n",
    "predictions, raw_outputs = model.predict(pre_df)\n",
    "import pickle\n",
    "import pandas as pd\n",
    "le = pickle.load(open('outputs/category_encoder.pkl', 'rb'))\n",
    "predictions=pd.DataFrame(le.inverse_transform(predictions),columns=['label'])\n",
    "save_df=pd.concat([df['id'],predictions],axis=1)\n",
    "save_df.to_csv('outputs/submission.csv',index=0)\n",
    "print('\\adone!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
