{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74eb4af5",
   "metadata": {},
   "source": [
    "# detail at https://cloud.tencent.com/developer/article/1531043\n",
    "### 安装simpletransformers。\n",
    "### pip install simpletransformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e49081",
   "metadata": {},
   "source": [
    "#### Simple Transformers要求数据必须包含在至少两列的Pandas DataFrames中。你只需为列的文本和标签命名，SimpleTransformers就会处理数据。或者你也可以遵循以下约定：\n",
    "\n",
    "•  第一列包含文本，类型为str。\n",
    "\n",
    "•  第二列包含标签，类型为int。\n",
    "\n",
    "对于多类分类，标签应该是从0开始的整数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56185a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(102832, 2) (102832, 2)\n",
      "['传热学主要介绍了导热、对流和辐射等课程内容的相关概念、定律、公式等。全书的重点是相关内容的例题详解和补充习题。带有答案的补充习题可帮助读者自我评估学习状况。'\n",
      " 17]\n"
     ]
    }
   ],
   "source": [
    "def load_data(data_csv):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    import pandas as pd\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    import numpy as np\n",
    "    import os\n",
    "    import pickle\n",
    "    df=pd.read_csv(data_csv,header=0)\n",
    "    \n",
    "    if 'id' in df.columns:\n",
    "        del df['id']\n",
    "    df.dropna(subset=['category'],inplace=True)\n",
    "    #exporting the departure encoder\n",
    "    if 'context' not in df.columns:\n",
    "        df.dropna(thresh=2,inplace=True)\n",
    "        df.fillna(value='', inplace=True)\n",
    "        df['context']=df['title']+df['summary']\n",
    "        del df['title']\n",
    "        del df['summary']\n",
    "    label_encoder='outputs/category_encoder.pkl'\n",
    "    if not os.path.exists(label_encoder):\n",
    "        if not os.path.exists('outputs'):\n",
    "            os.makedirs('outputs')\n",
    "        le = LabelEncoder()\n",
    "        df['category'] = le.fit_transform(df['category'])\n",
    "        output = open(label_encoder, 'wb')\n",
    "        pickle.dump(le, output)\n",
    "        output.close()\n",
    "    else:\n",
    "        le = pickle.load(open('outputs/category_encoder.pkl', 'rb'))\n",
    "        df['category'] = le.fit_transform(df['category'])\n",
    "    df.rename(columns={'context':'text','category':'labels'},inplace=True)\n",
    "    X,Y=df['text'],df['labels']\n",
    "    x_train, x_test, y_train,y_test = train_test_split(X, Y,test_size=0.3, random_state=10,stratify=Y)\n",
    "    train_df=pd.concat([x_train,y_train],axis=1)\n",
    "    test_df=pd.concat([x_test,y_test],axis=1)\n",
    "    \n",
    "    ###############################33\n",
    "    tra=pd.concat([X,Y],axis=1)\n",
    "    return tra,tra\n",
    "    \n",
    "    return train_df,test_df\n",
    "train_df,eval_df=load_data('data/Summary-train.csv')\n",
    "print(train_df.shape,eval_df.shape)\n",
    "print(train_df.values[1])\n",
    "#train_df.to_csv('data/split-train-title.csv',index=0)\n",
    "#eval_df.to_csv('data/split-test-title.csv',index=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a0bc9f-518f-409e-8389-57bd2e876434",
   "metadata": {},
   "source": [
    "## https://huggingface.co/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08a9bd33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at hfl/chinese-xlnet-mid were not used when initializing XLNetForSequenceClassification: ['lm_loss.bias', 'lm_loss.weight']\n",
      "- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at hfl/chinese-xlnet-mid and are newly initialized: ['logits_proj.weight', 'sequence_summary.summary.bias', 'sequence_summary.summary.weight', 'logits_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82028e7f01ef4e4bb1b770c92222ad86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/102832 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea7667556ac84463b1485a7b107482ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd4d0f5f2e8c4c9593850a055a60578b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 10:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dcab3a0c0714af4aaa77de9fdbda3dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 10:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e2ffcafcfec43688fee5b370f2f8964",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 10:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1361777ec764426bf5151aec91c8932",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 3 of 10:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dd948d5f3dd4a66b3cd3849994c8eb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 4 of 10:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1bec3ad4d9548dc83ec65a1cf290d3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 5 of 10:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f37fabc7c7545b297f32973b25de93c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 6 of 10:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f33736e505254711b3997ab13db835ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 7 of 10:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "553cc7b9a2f0482d96969811feaf9d72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 8 of 10:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86dd4e7b8faf488889a10389b4ef5f9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 9 of 10:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(16070, 0.15064805236368184)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from simpletransformers.model import TransformerModel\n",
    "from simpletransformers.classification import ClassificationModel\n",
    "\n",
    "import warnings\n",
    " \n",
    "warnings.filterwarnings('ignore')\n",
    "# Create a TransformerModel\n",
    "#model_type可以是['bert'，'xlnet'，'xlm'，'roberta'，'distilbert']之一。\n",
    "#要加载以前保存的模型而不是默认模型的模型，可以将model_name更改为包含已保存模型的目录的路径。\n",
    "'''\n",
    "model = TransformerModel('xlnet', 'hfl/chinese-xlnet-base', num_labels=22,\n",
    "                         args={'learning_rate':5e-5, 'num_train_epochs': 5, \n",
    "                               'reprocess_input_data': True, 'overwrite_output_dir': True,\n",
    "                              'max_seq_length': 40, 'train_batch_size': 64})\n",
    "'''\n",
    "model = ClassificationModel('xlnet', 'hfl/chinese-xlnet-mid', num_labels=22,use_cuda=True,\n",
    "                         args={'learning_rate':5e-5, 'num_train_epochs': 10,'use_early_stopping':True,'save_eval_checkpoints':False,'dataloader_num_workers':-1,\n",
    "                               'reprocess_input_data': True, 'overwrite_output_dir': True,'save_model_every_epoch':False,'n_gpu':-1,\n",
    "                              'max_seq_length':64, 'train_batch_size': 64,\"eval_batch_size\": 32,'best_model_dir':'outputs/final_best','evaluate_during_training':True})\n",
    "# Train the model\n",
    "model.train_model(train_df=train_df,eval_df=eval_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe7a8872",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "693a1f74225f40ad90253f92391c3db9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/102832 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45b6e3a773e84029a881f95ed49c94b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/12854 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mcc': 0.9993067969145869, 'f1': 0.9994165240392096, 'acc': 0.9994165240392096, 'eval_loss': 0.001716306218328234}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "def f1_multiclass(labels, preds):\n",
    "      return f1_score(labels, preds, average='micro')\n",
    "\n",
    "result, model_outputs, wrong_predictions = model.eval_model(eval_df, f1=f1_multiclass, acc=accuracy_score)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050d1859-9ab2-4a59-89ee-5e35b2deb4ff",
   "metadata": {},
   "source": [
    "### data v3--->TransformerModel('xlnet', 'hfl/chinese-xlnet-base'):{'mcc': 0.8599698093311049, 'f1': 0.882056401297729, 'acc': 0.882056401297729, 'eval_loss': 0.46453423575408004}\n",
    "\n",
    "### data gen-train--->TransformerModel('xlnet', 'hfl/chinese-xlnet-base'):{'mcc': 0.8807460285978498, 'f1': 0.899590062725342, 'acc': 0.899590062725342, 'eval_loss': 0.49068217969921585}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b8328a-3195-4829-9fab-84bb7192e063",
   "metadata": {},
   "source": [
    "#### 要加载以前保存的模型而不是默认模型的模型，可以将model_name更改为包含已保存模型的目录的路径。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af703c7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83961196b5d04b9986c7c7d5d97016a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/34045 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9189ff141e04998a6b861d4060ae159",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4256 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u0007done!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from simpletransformers.classification import ClassificationModel\n",
    "model = ClassificationModel('xlnet', 'outputs', num_labels=22,use_cuda=True,\n",
    "                         args={'learning_rate':5e-5, 'num_train_epochs': 10,'use_early_stopping':True,\n",
    "                               'reprocess_input_data': True, 'overwrite_output_dir': True,'save_model_every_epoch':False,\n",
    "                              'max_seq_length': 64, 'train_batch_size': 64})\n",
    "\n",
    "df=pd.read_csv('data/Summary-val.csv')\n",
    "if 'context' not in df.columns:\n",
    "    df.fillna(value='', inplace=True)\n",
    "    df['context']=df['title']+df['summary']\n",
    "pre_df=list(df['context'])\n",
    "predictions, raw_outputs = model.predict(pre_df)\n",
    "import pickle\n",
    "import pandas as pd\n",
    "le = pickle.load(open('outputs/category_encoder.pkl', 'rb'))\n",
    "predictions=pd.DataFrame(le.inverse_transform(predictions),columns=['label'])\n",
    "save_df=pd.concat([df['id'],predictions],axis=1)\n",
    "save_df.to_csv('outputs/submission.csv',index=0)\n",
    "print('\\adone!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1914018f-1073-4768-9ddf-82d856d3d9e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: outputs/ (stored 0%)\n",
      "  adding: outputs/category_encoder.pkl (deflated 23%)\n",
      "  adding: outputs/config.json (deflated 63%)\n",
      "  adding: outputs/pytorch_model.bin (deflated 7%)\n",
      "  adding: outputs/tokenizer_config.json (deflated 42%)\n",
      "  adding: outputs/special_tokens_map.json (deflated 49%)\n",
      "  adding: outputs/spiece.model (deflated 46%)\n",
      "  adding: outputs/tokenizer.json (deflated 58%)\n",
      "  adding: outputs/training_args.bin (deflated 49%)\n",
      "  adding: outputs/model_args.json (deflated 61%)\n",
      "  adding: outputs/eval_results.txt (deflated 30%)\n",
      "  adding: outputs/submission.csv (deflated 46%)\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    if False:\n",
    "        !apt-get -y update\n",
    "        !apt-get install zip\n",
    "    !zip -r out.zip outputs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
